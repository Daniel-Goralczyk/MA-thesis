{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using RoBERTa\n",
    "Load the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells the device to run the analysis on the GPU. I have CUDA installed on my machine. I did run this script from the command line which has used its own conda environment. This was the only way to have the GPU do this task successfully. Use of the CPU takes way longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Roberta\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reads in the data and the neccesary columns. I also initalize some variables here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_read = ['videoId', 'caption_text']\n",
    "file_path_df = r'new_data.feather'\n",
    "df = pd.read_feather(file_path_df, columns=columns_to_read)\n",
    "# Initialize variables\n",
    "processed_count = 0\n",
    "video_sentiment_scores = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the function that is used to collect the sentiment for each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text_to_window_size_and_predict_proba(input_ids, attention_mask, total_len, model, window_length=510):\n",
    "    logits_list = []\n",
    "    input_ids = [101] + input_ids + [102]\n",
    "    attention_mask = [1] + attention_mask + [1]\n",
    "    input_ids = torch.tensor(input_ids).to(device)\n",
    "    attention_mask = torch.tensor(attention_mask).to(device)\n",
    "\n",
    "    start = 0\n",
    "    while start < total_len:\n",
    "        end = start + window_length\n",
    "        if end >= total_len:\n",
    "            end = total_len\n",
    "\n",
    "        input_ids_chunk = input_ids[start:end]\n",
    "        attention_mask_chunk = attention_mask[start:end]\n",
    "\n",
    "        # Calculate token length for this specific chunk\n",
    "        token_length = len(input_ids_chunk)\n",
    "\n",
    "        input_dict = {\n",
    "            'input_ids': input_ids_chunk.unsqueeze(0).long(),\n",
    "            'attention_mask': attention_mask_chunk.unsqueeze(0).int()\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**input_dict)\n",
    "\n",
    "        logits_list.append((outputs.logits, token_length)) \n",
    "        \n",
    "        start = end\n",
    "\n",
    "    return logits_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a progress bar so I can see the progress. (44,100 videos to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rows(start_index, end_index):\n",
    "    global processed_count\n",
    "    global video_sentiment_scores\n",
    "\n",
    "    # Initialize the tqdm progress bar\n",
    "    with tqdm(total= end_index - start_index + 1, desc='Processing texts', unit='texts') as pbar:\n",
    "        for index in range(start_index, end_index + 1):\n",
    "            try:\n",
    "                row = df.iloc[index]\n",
    "                text = row['caption_text']\n",
    "                video_id = row['videoId']\n",
    "\n",
    "                # Tokenize the text to obtain input_ids and attention_mask\n",
    "                tokens = tokenizer.encode_plus(text, add_special_tokens=False)\n",
    "                input_ids = tokens['input_ids']\n",
    "                attention_mask = tokens['attention_mask']\n",
    "\n",
    "                # Chunk the text and predict probabilities for each segment\n",
    "                proba_list = chunk_text_to_window_size_and_predict_proba(input_ids, attention_mask, len(input_ids), model)\n",
    "\n",
    "                # Extend or create a list of segments for the video ID in the dictionary\n",
    "                if video_id in video_sentiment_scores:\n",
    "                    video_sentiment_scores[video_id].extend(proba_list)\n",
    "                else:\n",
    "                    video_sentiment_scores[video_id] = proba_list\n",
    "\n",
    "                pbar.update(1)\n",
    "                processed_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing text at index {index}: {e}\")\n",
    "                # Optionally handle or log the specific error\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines where the function should start and stop. Call 'process_rows' to run the function. Then save it.  \n",
    "For this example I went through 51 videos (index 50). Final index is 44099. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing texts: 100%|██████████| 51/51 [00:09<00:00,  5.29texts/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video sentiment scores saved to: video_sentiment_scores_local_sample.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_index = 0\n",
    "end_index = 50\n",
    "process_rows(start_index, end_index)\n",
    "video_sentiment_scores_cpu = defaultdict(list)\n",
    "\n",
    "for video_id, sentiment_scores in video_sentiment_scores.items():\n",
    "    video_sentiment_scores_cpu[video_id] = [\n",
    "        (scores.cpu().numpy(), token_length) for scores, token_length in sentiment_scores\n",
    "    ]\n",
    "\n",
    "save_folder = r'C:\\\\Users\\\\goral\\\\Documents\\\\Python\\\\Scripts\\\\SAVES'\n",
    "file_name = r\"video_sentiment_scores_local_sample\"\n",
    "save_path = os.path.join(save_folder, file_name + \".pkl\")\n",
    "with open(save_path, 'wb') as file:\n",
    "    pickle.dump(video_sentiment_scores_cpu, file)\n",
    "\n",
    "print(f\"Video sentiment scores saved to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
